{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2513,"status":"ok","timestamp":1660159886239,"user":{"displayName":"mdlaoe@126.com","userId":"13735632573663598827"},"user_tz":240},"id":"cmiXuwsko2Uc","outputId":"4798c1e2-597c-4bf9-bac9-a040b19de473"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import statsmodels.api as sm\n","import statsmodels.tools as st\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnSCRc1Mo5XY"},"outputs":[],"source":["def compute_W_sad(phi, psi, eta_phi, eta_psi, x, a, z, xx, max_iter, W_0, K_0):\n","\n","    \"\"\" Compute W^{sad} straightly\n","\n","    Parameters\n","    ----------\n","    phi : function\n","        Feature map. phi : S * A -> R^{d_{phi}}\n","    psi : function\n","        Feature map. psi : Z -> R^{d_{psi}}\n","    eta_phi: array\n","        Stepsize in the stochastic gradient. It is a numpy array with shape ''(1, T)''\n","    eta_psi: array\n","        Stepsize in the stochastic gradient. It is a numpy array with shape ''(1, T)''\n","    x : array\n","        It's a given state sample matrix. It can be a numpy matirx with shape ''(d_{x}, T)'', where T is the parameter iter.\n","    a : array\n","        It's a given action sample matrix. It can be a numpy matirx with shape ''(d_{a}, T)'', where T is the parameter iter.\n","    z : array\n","        It's a given instrumental variable sample matrix. It can be a numpy matirx with shape ''(d_{z}, T)'', where T is the parameter iter.\n","    xx : array\n","        It's a given next state sample matrix. It can be a numpy matirx with shape ''(d_{x}, T)'', where T is the parameter iter.\n","    max_iter : int\n","        Number of iterations.\n","    W_0 : array\n","        It's an initial guess for output W. W_0 can be a numpy matirx with shape ''(d_{x}, d_{phi})''.\n","    K_0 : array\n","        It's an initial guess for K. K_0 can be a numpy matirx with shape ''(d_{x}, d_{psi})''.\n","\n","    Output\n","    --------\n","    W_now : array\n","        It's an estimation matrix for the true W_sad with shape ''(d_{x}, d_{phi})''\n","    \"\"\"\n","\n","    W_now = W_0.copy()\n","    K_now = K_0.copy()\n","    W_next = W_0.copy()\n","    K_next = K_0.copy()\n","\n","    for t in range(max_iter):\n","        Phi = np.matrix(phi(x[:, t],a[:, t]))\n","        Psi = np.matrix(psi(x[:,t],z[:, t]))\n","        W_next = W_now - eta_phi[t] * np.dot(K_now,np.dot(Psi, np.transpose(Phi)))\n","        K_next = K_now + eta_psi[t] * (np.dot(K_now,np.dot(Psi, np.transpose(Psi))) + np.dot([xx[:, t]], np.transpose(Psi)) - np.dot(W_now, np.dot(Phi, np.transpose(Psi))))\n","        W_now = W_next.copy()\n","        K_now = K_next.copy()\n","\n","    return W_now\n","\n","\n","# Use mini batch stochastic gradient descent.\n","def compute_W_sad2(phi, psi, eta_phi, eta_psi, x, a, z, xx, max_iter, W_0, K_0, size, choose):\n","\n","    \"\"\" Compute W^{sad} straightly\n","\n","    Parameters\n","    ----------\n","    phi : function\n","        Feature map. phi : S * A -> R^{d_{phi}}\n","    eta_phi: array\n","        Stepsize in the stochastic gradient. It is a numpy array with shape ''(1, T)''\n","    x : array\n","        It's a given state sample matrix. It can be a numpy matirx with shape ''(d_{x}, T)'', where T is the parameter iter.\n","    a : array\n","        It's a given action sample matrix. It can be a numpy matirx with shape ''(d_{a}, T)'', where T is the parameter iter.\n","    z : array\n","        It's a given instrumental variable sample matrix. It can be a numpy matirx with shape ''(d_{z}, T)'', where T is the parameter iter.\n","    xx : array\n","        It's a given next state sample matrix. It can be a numpy matirx with shape ''(d_{x}, T)'', where T is the parameter iter.\n","    max_iter : int\n","        Number of iterations.\n","    W_0 : array\n","        It's an initial guess for output W. W_0 can be a numpy matirx with shape ''(d_{x}, d_{phi})''.\n","\n","    Output\n","    --------\n","    W_now : array\n","        It's an estimation matrix for the true W_sad with shape ''(d_{x}, d_{phi})''\n","    \"\"\"\n","\n","    W_now = W_0.copy()\n","    K_now = K_0.copy()\n","    W_next = W_0.copy()\n","    K_next = K_0.copy()\n","\n","    for i in range(int(max_iter/size)):\n","        A = np.zeros((feature_size, feature_size))\n","        B = np.zeros((feature_size, feature_size))\n","        C = np.zeros((5, feature_size))\n","        for j in range(size):\n","            Phi = phi(np.transpose(np.array([x[:,i * size + j]])),np.transpose(np.array([a[:,i * size + j]])))\n","            Psi = psi(np.transpose(np.array([x[:,i * size + j]])),np.transpose(np.array([z[:,i * size + j]])))\n","            A = A + 1/size * np.dot(Psi, np.transpose(Phi))\n","            B = B + 1/size * np.dot(Psi, np.transpose(Psi))\n","            C = C + 1/size * np.dot(np.transpose(np.array([xx[:,i * size + j]])),np.transpose(Psi))\n","\n","        A = np.float64(A)\n","        B = np.float64(B)\n","        C = np.float64(C)\n","\n","        for j in range(200):\n","            K_next = K_now + eta_psi[j] * (np.dot(K_now, B) + C - np.dot(W_now, np.transpose(A)))\n","            K_now = K_next.copy()\n","        W_next = W_now - eta_phi[i] * np.dot(K_now, A)\n","        W_now = W_next.copy()\n","\n","    return W_now\n","\n","\n","def phi(x,a):\n","\n","    \"\"\"\n","    The feature map\n","    :param x: a state. The shape is ''(d_{x}, 1)''\n","    :param a: an action. The shape is ''(d_{a}, 1)''\n","    :return:\n","    \"\"\"\n","    return np.vstack([[1],x,a])\n","\n","\n","def psi(x,z):\n","\n","    \"\"\"\n","    The feature map\n","    :param z: an instrumental variable. The shape is ''(d_{z}, 1)''\n","    :return:\n","    \"\"\"\n","    return np.vstack([[1],x,z])\n","\n","\n","def generate_action(x,z,e):\n","\n","    \"\"\"\n","    A function to generate action while collecting data.\n","    \"\"\"\n","    Identity = np.eye(5)\n","    Cov = Identity + np.diag([0.3,0.3,0.3,0.3],k=1) + np.diag([0.3,0.3,0.3,0.3],k=-1)\n","    return np.clip(np.random.multivariate_normal(mean=np.ndarray.flatten(z+e), cov=Cov),-1,1)\n","\n","def F(x, a):\n","\n","    \"\"\"\n","    A deterministic transition function we want to approach.\n","    \"\"\"\n","    P = 0.5 * np.eye(5)\n","    P = P + np.diag([0.2,0.2,0.2,0.2],k=1) + np.diag([0.2,0.2,0.2,0.2],k=-1)\n","    Q = 0.5 * np.eye(5)\n","    Q = Q + np.diag([0.1,0.1,0.1,0.1],k=1) + np.diag([0.1,0.1,0.1,0.1],k=-1)\n","    return np.dot(P,x) - np.dot(Q,a)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_y0uu4RYeqM6"},"outputs":[],"source":["sigma_e_list = [1,1,1]\n","sigma_z_list = [0.5,1,1.5]\n","\n","\n","for choose in range(3):\n","    sigma_e = sigma_e_list[choose]\n","    sigma_z = sigma_z_list[choose]\n","\n","    # Data collection\n","    feature_size = 11\n","    max_iter = 20000\n","    size = 256\n","    horizon = 1000\n","\n","    Mean = np.zeros(5)\n","    Identity = np.eye(5)\n","\n","    Cov = Identity + np.diag([0.3,0.3,0.3,0.3],k=1) + np.diag([0.3,0.3,0.3,0.3],k=-1)\n","\n","    x = np.array([[10],[10],[10],[10],[10]])  # initial state\n","    z = np.array(np.transpose([np.random.multivariate_normal(mean=Mean, cov=sigma_z * Identity)]))\n","    e = np.array(np.transpose([np.random.multivariate_normal(mean=Mean, cov=sigma_e * Cov)]))\n","    a = np.array(np.transpose([generate_action(x,z,e)]))  # get the action\n","    x_next = np.array(F(x,a)+e)  # get the next state\n","    xx = x_next.copy()  # store the next state\n","\n","\n","    # Collecting the data step by step\n","    for i in range(max_iter):\n","        if i % horizon == 0:\n","            x_next = 10 * np.ones((5,1))  \n","        x = np.hstack((x,x_next))\n","        z_next = np.array(np.transpose([np.random.multivariate_normal(mean=Mean, cov=sigma_z * Identity)]))\n","        e_next = np.array(np.transpose([np.random.multivariate_normal(mean=Mean, cov=sigma_e * Cov)]))\n","        z = np.hstack((z,z_next))\n","        e = np.hstack((e,e_next))\n","        a_next = np.array(np.transpose([generate_action(x[:,i+1],z[:,i+1],e[:,i+1])]))\n","        x_next = np.array(F(x_next,a_next)+e_next)\n","        a = np.hstack((a,a_next))\n","        xx = np.hstack((xx,x_next))\n","\n","    A = np.zeros((feature_size,feature_size))\n","    B = np.zeros((feature_size,feature_size))\n","    C = np.zeros((5,feature_size))\n","    for i in range(max_iter):\n","        Phi = phi(np.transpose(np.array([x[:,i]])),np.transpose(np.array([a[:,i]])))\n","        Psi = psi(np.transpose(np.array([x[:,i]])),np.transpose(np.array([z[:,i]])))\n","        A = A + 1/max_iter * np.dot(Psi, np.transpose(Phi))\n","        B = B + 1/max_iter * np.dot(Psi, np.transpose(Psi))\n","        C = C + 1/max_iter * np.dot(np.transpose(np.array([xx[:,i]])),np.transpose(Psi))\n","\n","    # Compute Closed Form\n","    # The closed form for W^{*} is CB^{-1}A(A^{T}B^{-1}A)^{-1}\n","    # use sample to estimate covariance matrices\n","    A = np.float64(A)\n","    B = np.float64(B)\n","    C = np.float64(C)\n","    W_front = np.dot(np.dot(C,np.linalg.inv(B)),A)  # compute CB^{-1}A\n","    W_back = np.dot(np.dot(np.transpose(A),np.linalg.inv(B)), A)  # compute A^{T}B^{-1}A\n","    W_star = np.dot(W_front, np.linalg.inv(W_back))\n","    strength = np.linalg.eig(np.dot(np.dot(np.transpose(A),np.linalg.inv(B)),A))\n","    print('Eigenvalue',strength[0])\n","\n","\n","    # Compute W by using Gradient Descent\n","    W_0 = 0.2 * np.ones((5,feature_size))  # initial guess\n","    K_0 = np.zeros((5,feature_size))  # initial guess\n","    eta_phi = np.zeros(max_iter)\n","    eta_psi = np.zeros(max_iter)\n","    # setup for stepsize\n","    for i in range(max_iter):\n","        eta_psi[i] = -1/(20+i)\n","        eta_phi[i] = 0.18+ 1/(10+i)\n","    W_sad = compute_W_sad2(phi, psi, eta_phi, eta_psi, x, a, z, xx, max_iter, W_0, K_0, size, choose)\n","    print(W_sad)\n","    #\n","    #\n","    print('Ordinary Regression Result: ')\n","    Y1 = pd.DataFrame(np.transpose(xx[0]))\n","    Y2 = pd.DataFrame(np.transpose(xx[1]))\n","    Y3 = pd.DataFrame(np.transpose(xx[2]))\n","    Y4 = pd.DataFrame(np.transpose(xx[3]))\n","    Y5 = pd.DataFrame(np.transpose(xx[4]))\n","    variable = np.vstack((x,a))\n","    variable = np.transpose(variable)\n","    X = pd.DataFrame(variable)\n","    X = st.tools.add_constant(X)\n","    result1 = sm.OLS(Y1,X).fit()\n","    result2 = sm.OLS(Y2,X).fit()\n","    result3 = sm.OLS(Y3,X).fit()\n","    result4 = sm.OLS(Y4,X).fit()\n","    result5 = sm.OLS(Y5,X).fit()\n","    regression = np.zeros((5,11))\n","    list = ['const', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    for i in range(11):\n","        regression[0,i] = result1.params[list[i]]\n","        regression[1,i] = result2.params[list[i]]\n","        regression[2,i] = result3.params[list[i]]\n","        regression[3,i] = result4.params[list[i]]\n","        regression[4,i] = result5.params[list[i]]\n","    print(regression)\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"parametric.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.7.11 ('IEORE_4008')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.11"},"vscode":{"interpreter":{"hash":"b88fb9f329836ff1404a7f543788882dcbb1ea6ac433f8e88a63f43427e5ba35"}}},"nbformat":4,"nbformat_minor":0}
