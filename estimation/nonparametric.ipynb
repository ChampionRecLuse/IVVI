{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TVfmZTKteSF9"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import statsmodels.api as sm\n","import statsmodels.tools as st\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EIenFu1JeQgO"},"outputs":[],"source":["def compute_W_sad(phi, psi, eta_phi, eta_psi, x, a, z, xx, max_iter, W_0, K_0):\n","\n","    \"\"\" Compute W^{sad} straightly\n","\n","    Parameters\n","    ----------\n","    phi : function\n","        Feature map. phi : S * A -> R^{d_{phi}}\n","    psi : function\n","        Feature map. psi : Z -> R^{d_{psi}}\n","    eta_phi: array\n","        Stepsize in the stochastic gradient. It is a numpy array with shape ''(1, T)''\n","    eta_psi: array\n","        Stepsize in the stochastic gradient. It is a numpy array with shape ''(1, T)''\n","    x : array\n","        It's a given state sample matrix. It can be a numpy matirx with shape ''(d_{x}, T)'', where T is the parameter iter.\n","    a : array\n","        It's a given action sample matrix. It can be a numpy matirx with shape ''(d_{a}, T)'', where T is the parameter iter.\n","    z : array\n","        It's a given instrumental variable sample matrix. It can be a numpy matirx with shape ''(d_{z}, T)'', where T is the parameter iter.\n","    xx : array\n","        It's a given next state sample matrix. It can be a numpy matirx with shape ''(d_{x}, T)'', where T is the parameter iter.\n","    max_iter : int\n","        Number of iterations.\n","    W_0 : array\n","        It's an initial guess for output W. W_0 can be a numpy matirx with shape ''(d_{x}, d_{phi})''.\n","    K_0 : array\n","        It's an initial guess for K. K_0 can be a numpy matirx with shape ''(d_{x}, d_{psi})''.\n","\n","    Output\n","    --------\n","    W_now : array\n","        It's an estimation matrix for the true W_sad with shape ''(d_{x}, d_{phi})''\n","    \"\"\"\n","\n","    W_now = W_0.copy()\n","    K_now = K_0.copy()\n","    W_next = W_0.copy()\n","    K_next = K_0.copy()\n","\n","    for t in range(max_iter):\n","        Phi = np.matrix(phi(x[:, t],a[:, t]))\n","        Psi = np.matrix(psi(x[:,t],z[:, t]))\n","        W_next = W_now - eta_phi[t] * np.dot(K_now,np.dot(Psi, np.transpose(Phi)))\n","        K_next = K_now + eta_psi[t] * (np.dot(K_now,np.dot(Psi, np.transpose(Psi))) + np.dot([xx[:, t]], np.transpose(Psi)) - np.dot(W_now, np.dot(Phi, np.transpose(Psi))))\n","        W_now = W_next.copy()\n","        K_now = K_next.copy()\n","\n","    return W_now\n","\n","\n","# Use mini batch stochastic gradient descent.\n","def compute_W_sad2(phi, psi, eta_phi, eta_psi, x, a, z, xx, max_iter, W_0, K_0, size, feature_size, choose):\n","\n","    \"\"\" Compute W^{sad} straightly\n","\n","    Parameters\n","    ----------\n","    phi : function\n","        Feature map. phi : S * A -> R^{d_{phi}}\n","    eta_phi: array\n","        Stepsize in the stochastic gradient. It is a numpy array with shape ''(1, T)''\n","    x : array\n","        It's a given state sample matrix. It can be a numpy matirx with shape ''(d_{x}, T)'', where T is the parameter iter.\n","    a : array\n","        It's a given action sample matrix. It can be a numpy matirx with shape ''(d_{a}, T)'', where T is the parameter iter.\n","    z : array\n","        It's a given instrumental variable sample matrix. It can be a numpy matirx with shape ''(d_{z}, T)'', where T is the parameter iter.\n","    xx : array\n","        It's a given next state sample matrix. It can be a numpy matirx with shape ''(d_{x}, T)'', where T is the parameter iter.\n","    max_iter : int\n","        Number of iterations.\n","    W_0 : array\n","        It's an initial guess for output W. W_0 can be a numpy matirx with shape ''(d_{x}, d_{phi})''.\n","\n","    Output\n","    --------\n","    W_now : array\n","        It's an estimation matrix for the true W_sad with shape ''(d_{x}, d_{phi})''\n","    \"\"\"\n","\n","    W_now = W_0.copy()\n","    K_now = K_0.copy()\n","    W_next = W_0.copy()\n","    K_next = K_0.copy()\n","\n","    for i in range(int(max_iter/size)):\n","        A = np.zeros((feature_size, feature_size))\n","        B = np.zeros((feature_size, feature_size))\n","        C = np.zeros((1, feature_size))\n","        for j in range(size):\n","            Phi = phi(np.array([x[:, i * size + j]]), np.array([a[:, i * size + j]]))\n","            Psi = psi(np.array([x[:, i * size + j]]), np.array([z[:, i * size + j]]))\n","            A = A + 1 / size * np.dot(Psi, np.transpose(Phi))\n","            B = B + 1 / size * np.dot(Psi, np.transpose(Psi))\n","            C = C + 1 / size * np.dot(np.array([xx[:, i * size + j]]), np.transpose(Psi))\n","\n","        A = np.float64(A)\n","        B = np.float64(B)\n","        C = np.float64(C)\n","        for j in range(150):\n","            K_next = K_now + eta_psi[j] * (np.dot(K_now, B) + C - np.dot(W_now, np.transpose(A)))\n","            K_now = K_next.copy()\n","        W_next = W_now - eta_phi[i] * np.dot(K_now, A)\n","        W_now = W_next.copy()\n","\n","    return W_now\n","\n","\n","def phi(x,a):\n","\n","    \"\"\"\n","    The feature map\n","    :param x: a state. The shape is ''(d_{x}, 1)''\n","    :param a: an action. The shape is ''(d_{a}, 1)''\n","    :return:\n","    \"\"\"\n","    return np.array([[1], x, a, x**2, a**2, x**3, a**3])\n","\n","def psi(x,z):\n","\n","    \"\"\"\n","    The feature map\n","    :param z: an instrumental variable. The shape is ''(d_{z}, 1)''\n","    :return:\n","    \"\"\"\n","    return np.array([[1], x, z, x**2, z**2, x**3, z**3])\n","\n","def generate_action(x,z,e):\n","\n","    \"\"\"\n","    A function to generate action while collecting data.\n","    \"\"\"\n","\n","    return np.clip(np.random.normal(z+e, 0.5), -1, 1)\n","    # return np.random.normal(z+e,1)\n","\n","def F(x, a):\n","\n","    \"\"\"\n","    A deterministic transition function we want to approach.\n","    \"\"\"\n","\n","    return np.log(np.abs(x-1) + 1) - 1/2 * a** 3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PaT4uz3eUnt"},"outputs":[],"source":["sigma_e_list = [1,1,1]\n","sigma_z_list = [0.8,0.9,1.5]\n","\n","for choose in range(3):\n","    sigma_e = sigma_e_list[choose]\n","    sigma_z = sigma_z_list[choose]\n","\n","    # Data collection\n","    max_iter = 80000\n","    size = 256\n","    horizon = 1000\n","    feature_size = 7\n","\n","    x = np.array([[0]])  # initial state\n","    z = np.array([[np.random.normal(loc=0, scale=sigma_z)]])\n","    e = np.array([[np.random.normal(loc=0, scale=sigma_e)]])\n","    a = np.array(generate_action(x,z,e))  # get the action\n","    x_next = np.array(F(x,a)+e)  # get the next state\n","    xx = x_next.copy()  # store the next state\n","\n","    # Collecting the data step by step\n","    for i in range(max_iter):\n","        if i % horizon == 0:\n","            x_next = np.zeros((1,1)) \n","        x = np.hstack((x,x_next))\n","        z_next = np.array([[np.random.normal(loc=0, scale=sigma_z)]])\n","        e_next = np.array([[np.random.normal(loc=0, scale=sigma_e)]])\n","        # e_next = np.array([[1]])\n","        z = np.hstack((z,z_next))\n","        e = np.hstack((e,e_next))\n","        a_next = np.array([generate_action(x[:,i+1],z[:,i+1],e[:,i+1])])\n","        x_next = np.array(F(x_next,a_next)+e_next)\n","        a = np.hstack((a,a_next))\n","        xx = np.hstack((xx,x_next))\n","\n","\n","    A = np.zeros((feature_size,feature_size))\n","    B = np.zeros((feature_size,feature_size))\n","    C = np.zeros((1,feature_size))\n","    for i in range(max_iter):\n","        Phi = phi(np.array([x[:,i]]),np.array([a[:,i]]))\n","        Psi = psi(np.array([x[:,i]]),np.array([z[:,i]]))\n","        A = A + 1/max_iter * np.dot(Psi, np.transpose(Phi))\n","        B = B + 1/max_iter * np.dot(Psi, np.transpose(Psi))\n","        C = C + 1/max_iter * np.dot(np.array([xx[:,i]]),np.transpose(Psi))\n","\n","    # Compute Closed Form\n","    # The closed form for W^{*} is CB^{-1}A(A^{T}B^{-1}A)^{-1}\n","    # use sample to estimate covariance matrices\n","    A = np.float64(A)\n","    B = np.float64(B)\n","    C = np.float64(C)\n","    W_front = np.dot(np.dot(C,np.linalg.inv(B)),A)  # compute CB^{-1}A\n","    W_back = np.dot(np.dot(np.transpose(A),np.linalg.inv(B)), A)  # compute A^{T}B^{-1}A\n","    W_star = np.dot(W_front, np.linalg.inv(W_back))\n","    strength = np.linalg.eig(np.dot(np.dot(np.transpose(A),np.linalg.inv(B)),A))\n","\n","    # Compute W by using Gradient Descent\n","    W_0 = 0 * np.ones((1,feature_size))  # initial guess\n","    K_0 = np.zeros((1,feature_size))  # initial guess\n","    eta_phi = np.zeros(max_iter)\n","    eta_psi = np.zeros(max_iter)\n","    # setup for stepsize\n","    for i in range(max_iter):\n","        eta_psi[i] = -1/(100+5*i)\n","        eta_phi[i] = 1/(25+i)\n","    W_sad = compute_W_sad2(phi, psi, eta_phi, eta_psi, x, a, z, xx, max_iter, W_0, K_0, size, feature_size, choose)\n","    print(W_sad)\n","    #\n","    #\n","    print('Ordinary Regression Result: ')\n","    Y = pd.DataFrame(np.transpose(xx))\n","    variable = np.vstack((x,a,x**2,a**2,x**3,a**3))\n","    variable = np.transpose(variable)\n","    X = pd.DataFrame(variable)\n","    X = st.tools.add_constant(X)\n","    result = sm.OLS(Y,X).fit()\n","    list = ['const', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    regression = np.zeros((1,feature_size))\n","    for i in range(feature_size):\n","        regression[0,i] = result.params[list[i]]\n","    print(regression)\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"nonparametric.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.7.11 ('IEORE_4008')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"vscode":{"interpreter":{"hash":"b88fb9f329836ff1404a7f543788882dcbb1ea6ac433f8e88a63f43427e5ba35"}}},"nbformat":4,"nbformat_minor":0}
